## Portable LLama2

[en](./docs/README_en.md) | [中文](./README_cn.md) 


本项目通过 wasm 技术将 LLama2 模型加载到浏览器中，实现web端的高效推理运算。

### 模型训练

( 整理中 coming soon ... ）

### wasm 编译

( 整理中 coming soon ... ）


### 客户端安装

1. [安装node环境](https://nodejs.org)

2. 安装node包 ```npm install```


3. 运行web服务


[在线demo](https://hku.github.io/pages/portable-llama2/)


### 相关资源

[模型]() | [中文](./docs/README_cn.md) | git


在垂直细分场景下，portable 模型在算力节省，响应提速，数据隐私等方面有着明显的优势，对 portable 模型技术方向感兴趣的朋友，欢迎一起交流 ~

wx：


<img alt ="qrcode" src="./client/assets/qrcode2.jpg" width="300" height="auto">






