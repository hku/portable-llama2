## Portable LLama2

[en](./README.md) | [中文](./docs/README_cn.md) 


本项目通过 wasm 技术将 LLama2 模型加载到浏览器中，实现web端的高效推理运算。

### 模型训练

( 整理中 coming soon ... ）

### wasm 编译

( 整理中 coming soon ... ）


### 客户端展示



[在线demo](https://hku.github.io/pages/portable-llama2/)


### 相关资源

[en](./README.md) | [中文](./docs/README_cn.md)


在垂直细分场景下，portable 模型在算力节省，响应提速，数据隐私等方面有着明显的优势，对 portable 模型技术方向感兴趣的朋友，欢迎一起交流 ~

wx：


<img alt ="qrcode" src="./client/assets/qrcode2.jpg" width="300" height="auto">






